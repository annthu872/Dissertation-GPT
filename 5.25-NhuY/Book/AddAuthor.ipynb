{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "GPT_MODEL_4 = \"gpt-4-0125-preview\"\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "model = GPT_MODEL_4\n",
    "\n",
    "def ask(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "      response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def askNoJSON(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_to_txt_raw(json_data, file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for test_case, details in json_data.items():\n",
    "            file.write(f\"Test Case: {test_case}\\n\")\n",
    "            for key, value in details.items():\n",
    "                if isinstance(value, list):\n",
    "                    file.write(f\"{key}:\\n\")\n",
    "                    for item in value:\n",
    "                        file.write(f\"  - {item}\\n\")\n",
    "                else:\n",
    "                    file.write(f\"{key}: {value}\\n\")\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_to_txt(json_data, file_name):\n",
    "    filtered_data = {k: v for k, v in json_data.items() if v.get(\"reflect\") == \"yes\"}\n",
    "    with open(file_name, 'w') as file:\n",
    "        for test_case, details in filtered_data.items():\n",
    "            file.write(f\"Test Case: {test_case}\\n\")\n",
    "            for key, value in details.items():\n",
    "                if isinstance(value, list):\n",
    "                    file.write(f\"{key}:\\n\")\n",
    "                    for item in value:\n",
    "                        file.write(f\"  - {item}\\n\")\n",
    "                else:\n",
    "                    file.write(f\"{key}: {value}\\n\")\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_8=\"\"\"\n",
    "I want you to act as a software tester.\n",
    "Your task is to read the test scenario's name and the corresponding use case specification to base on those information for generateing test steps for test cases and their following expected result.\n",
    "Return the test cases in json format.\n",
    "The JSON format should follow the following structure:\n",
    "{\n",
    "  \"Test Case 1\":[\n",
    "    \"testCaseName\": \"Clear name of the test case so tester know what to test when they first read\",\n",
    "    \"objective\": \"Verify who doing what action or function in the test case and the summary of the final result of the test case\",\n",
    "    \"testSteps\": [\n",
    "      \"Step 1: Describe the step.\",\n",
    "      \"Step 2: Describe the step.\",\n",
    "      \"Step 3: Describe the step.\"\n",
    "    ],\n",
    "    \"expectedResult\": \"You inform the tester what should they see after doing all the steps\",\n",
    "    \"explanation\": \"Why do you create this test case? How does this test case related to the test scenario inputed?\",\n",
    "  ],\n",
    "}\n",
    "If there are more than one test case for this scenario, continue writing other test case in this form.\n",
    "\n",
    "Rules for generating test steps:\n",
    "- Describe the test step clearly to make sure each test case is independent, tester do not need to read other information (example: other test case, use case specification) to know how to do that step.\n",
    "- Avoid references to other test cases or instructions like \"do as mentioned.\"\n",
    "- If the test case need to be repeated to test with different order, data or case, seperate them to be distinct test cases.\n",
    "- If the scenario is about testing the displation and there is no flow directly cover that scenario, use only the basic (or main) flow to test it.\n",
    "- If there are use cases mentioned in extended or included use case, create test case combine use cases, Try to find the connection point of use cases for combination. \n",
    "- For test scenarios mentioning navigation in the name, only produce test cases related to the specified navigation method. \n",
    "(Example: \"Scenario: User navigates to a page by navbar\", only produce a test case of user navigates to that page by navbar even though the use case description has many way to navigate to that page)\n",
    "- For test scenarios not mentioning navigation in the name, do not include any navigation test cases.\n",
    "- Generate test cases that directly match the scenario name. Choose only one flow to cover the scenario.\n",
    "- Ensure all actions and objectives match the scenario name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELF_REF=\"\"\"\n",
    "Given a test scenario and test cases to test that given test scenario.\n",
    "Mark if test case can test the given test scenario or not through test steps, expected output, objective (although if it test other use case path or flow, if it is not used to test the given test scenario.)\n",
    "And give explanation why you think the resulted test case reflect the given test scenario or not. \n",
    "Your response should keep the format of the inserted test cases.\n",
    "The JSON format should follow the following structure:\n",
    "{\n",
    "  \"Test Case 1\":[\n",
    "    \"testCaseName\": \"Clear name of the test case so tester know what to test when they first read\",\n",
    "    \"objective\": \"Verify who doing what action or function in the test case and the summary of the final result of the test case\",\n",
    "    \"testSteps\": [\n",
    "      \"Step 1: Describe the step.\",\n",
    "      \"Step 2: Describe the step.\",\n",
    "      \"Step 3: Describe the step.\"\n",
    "    ],\n",
    "    \"expectedResult\": \"You inform the tester what should they see after doing all the steps\",\n",
    "    \"reflect\": \"yes/no\",\n",
    "    \"explanation\": \"explain why you think this test case reflect the given test scenario or not\",\n",
    "  ],\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "\"User navigates to 'Books' before submitting data\",\"User navigates to 'Genres' before submitting data\",\n",
    "\"User navigates to 'Authors' before submitting data\",\"User navigates to 'Home' before submitting data\",\n",
    "\"User navigates to 'API' before submitting data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_uc = \"\"\"\n",
    "Add a new author\n",
    "Description\n",
    "The creation page is designed to create a record of the new author in the database.\n",
    "\n",
    "Main scenario:\n",
    "User clicks the \"Create new\" button in the author list page;\n",
    "Application displays form to enter book data;\n",
    "User enters book data and presses \"Submit\" button;\n",
    "If any data is entered incorrectly, incorrect data messages are displayed;\n",
    "If entered data is valid, then record is adding to database;\n",
    "If error occurs, then error message is displaying;\n",
    "If new author record is successfully added, then list of authors with added records is displaying.\n",
    "\n",
    "Cancel operation scenario:\n",
    "User clicks the \"Create new\" button in the author list page;\n",
    "Application displays form to enter author data;\n",
    "User may start entering the data into the form fields;\n",
    "Before pressing \"Submit\" button user presses “Cancel” button;\n",
    "Data doesn’t save in the database, then a list of authors records is displayed to the user;\n",
    "If the user selects the menu item \"Books”, \"Genres”, \"Authors\", \"Home\" or \"API\", the data will not be saved to the database, and the corresponding form with updated data will be opened.\n",
    "\n",
    "When creating a new author, the following details are entered:\n",
    "Name\n",
    "Bio - author's biography\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_PROMPT=\"\"\"\n",
    "Generate test scenarios for me based on this use case description.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Test Scenario 1: Successful Author Creation\n",
      "\n",
      "**Objective**: Verify that a new author record can be successfully added to the database.\n",
      "\n",
      "**Steps**:\n",
      "1. Navigate to the author list page.\n",
      "2. Click the \"Create new\" button.\n",
      "3. Fill in the author's name and biography in the provided form fields.\n",
      "4. Click the \"Submit\" button.\n",
      "\n",
      "**Expected Result**:\n",
      "- The application validates the data and adds the new author record to the database.\n",
      "- The user is redirected to the updated list of authors, including the newly added author.\n",
      "\n",
      "### Test Scenario 2: Validation of Author Data\n",
      "\n",
      "**Objective**: Ensure that the application validates the input data correctly.\n",
      "\n",
      "**Steps**:\n",
      "1. Navigate to the author list page.\n",
      "2. Click the \"Create new\" button.\n",
      "3. Enter invalid data into the form fields (e.g., leaving the name field empty).\n",
      "4. Click the \"Submit\" button.\n",
      "\n",
      "**Expected Result**:\n",
      "- The application displays messages indicating which data was entered incorrectly.\n",
      "- The record is not added to the database.\n",
      "\n",
      "### Test Scenario 3: Cancel Operation Before Submission\n",
      "\n",
      "**Objective**: Verify that the cancel operation works correctly before submitting the form.\n",
      "\n",
      "**Steps**:\n",
      "1. Navigate to the author list page.\n",
      "2. Click the \"Create new\" button.\n",
      "3. Start entering data into the form fields.\n",
      "4. Click the \"Cancel\" button before submitting the form.\n",
      "\n",
      "**Expected Result**:\n",
      "- The data is not saved in the database.\n",
      "- The user is redirected to the list of author records.\n",
      "\n",
      "### Test Scenario 4: Navigation Away from Form\n",
      "\n",
      "**Objective**: Confirm that navigating away from the form discards the entered data.\n",
      "\n",
      "**Steps**:\n",
      "1. Navigate to the author list page and click the \"Create new\" button.\n",
      "2. Start entering author data into the form fields.\n",
      "3. Without submitting, select another menu item like \"Books\" or \"Home\".\n",
      "\n",
      "**Expected Result**:\n",
      "- The entered data is not saved to the database.\n",
      "- The application displays the selected page with updated data.\n",
      "\n",
      "### Test Scenario 5: Error Handling on Data Submission\n",
      "\n",
      "**Objective**: Test the application's error handling when an error occurs during data submission.\n",
      "\n",
      "**Steps**:\n",
      "1. Navigate to the author list page.\n",
      "2. Click the \"Create new\" button and enter valid author data.\n",
      "3. Simulate a database or server error (this may require a test environment setup to force an error condition).\n",
      "4. Click the \"Submit\" button.\n",
      "\n",
      "**Expected Result**:\n",
      "- The application displays an appropriate error message indicating that the record could not be added.\n",
      "- The user remains on the form page or is provided with options to retry or cancel.\n",
      "\n",
      "### Test Scenario 6: Field Limit Validation\n",
      "\n",
      "**Objective**: Ensure that the form fields enforce character limits.\n",
      "\n",
      "**Steps**:\n",
      "1. Navigate to the author list page.\n",
      "2. Click the \"Create new\" button.\n",
      "3. Enter data that exceeds the maximum allowed characters in the \"Name\" and \"Bio\" fields.\n",
      "4. Attempt to submit the form.\n",
      "\n",
      "**Expected Result**:\n",
      "- The application prevents submission and displays a message indicating the character limit for each field.\n",
      "- The record is not added to the database until the data complies with the character limits.\n",
      "\n",
      "### Test Scenario 7: Special Characters Handling in Author Data\n",
      "\n",
      "**Objective**: Verify that the form correctly handles special characters in the author's name and biography.\n",
      "\n",
      "**Steps**:\n",
      "1. Navigate to the author list page.\n",
      "2. Click the \"Create new\" button.\n",
      "3. Enter a name and biography that include special characters (e.g., accents, symbols).\n",
      "4. Click the \"Submit\" button.\n",
      "\n",
      "**Expected Result**:\n",
      "- The application correctly stores and displays the author's name and biography with special characters.\n",
      "- The new author record is successfully added to the database and displayed in the author list.\n"
     ]
    }
   ],
   "source": [
    "promptTestCase = [\n",
    "{ \"role\": \"system\", \"content\": BASELINE_PROMPT},\n",
    "{ \"role\": \"user\", \"content\": prompt_uc}\n",
    "]\n",
    "gpt_response = askNoJSON(promptTestCase, client, model)\n",
    "print(gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in scenarios:\n",
    "    i = 1\n",
    "    while(i<=1):\n",
    "        try: \n",
    "            promptTestCase = [\n",
    "            { \"role\": \"system\", \"content\": SYSTEM_PROMPT_8},\n",
    "            { \"role\": \"user\", \"content\": scenario + \"\\n\" + prompt_uc}\n",
    "            ]\n",
    "            gpt_response = ask(promptTestCase, client, model)\n",
    "            json_data = json.loads(gpt_response)\n",
    "            write_json_to_txt_raw(json_data, scenario + \"-Raw\" + str(i) + \".txt\")\n",
    "\n",
    "            promptSelfRef = [\n",
    "                { \"role\": \"system\", \"content\": SELF_REF},\n",
    "                { \"role\": \"user\", \"content\": scenario + \"\\n\" + gpt_response}\n",
    "            ]\n",
    "            final_response = ask(promptSelfRef, client, model)\n",
    "            json_fin = json.loads(final_response)\n",
    "            write_json_to_txt(json_fin, scenario + str(i) + \".txt\")\n",
    "            i+=1\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred with scenario '{scenario}' iteration {i}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
