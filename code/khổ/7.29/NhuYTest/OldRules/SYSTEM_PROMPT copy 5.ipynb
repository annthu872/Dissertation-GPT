{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "GPT_MODEL_4 = \"gpt-4-0125-preview\"\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "model = GPT_MODEL_4\n",
    "\n",
    "def ask(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def askJSON(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "      response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "def read_file_content(file_path):\n",
    "    # Detect the encoding\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "    \n",
    "    # Read the file with the detected encoding\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at path {file_path} was not found.\"\n",
    "    except UnicodeDecodeError:\n",
    "        return f\"Error: The file at path {file_path} cannot be decoded with the {encoding} encoding.\"\n",
    "    except IOError:\n",
    "        return f\"Error: An I/O error occurred while reading the file at path {file_path}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_string_to_file(filename, content):\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(content)\n",
    "        print(f\"String has been written to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "I want you to act as software tester.\n",
    "Your task is to read this information about a use case.\n",
    "Then you predict all scenarios that can happen in this use case.\n",
    "\n",
    "Rules of generating scenarios you should follow:\n",
    "- Positive test scenarios are scenarios generating from main flow or basic fow or alternative flows. Only create one test scenarios to test the baisc flow (main flow) with all valid conditions.\n",
    "- Negative test scenarios are scenarios generating from exception flows. One exception flow or one alternative flow can have multiple test scenarios according to the conditions extracted from the flow. Each invalid condition in flows must have a test scenario.\n",
    "- Scenarios involve executing all steps within a specific flow with varied data or actions.\n",
    "- Scenarios should be independent and require a complete flow to proceed.\n",
    "- A scenario encompasses a whole function, not just verifying individual steps.\n",
    "- Each flow must have at least one test scenario to cover the flow.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase_path = r\"C:\\Users\\congc\\Desktop\\GPT\\Dissertation-GPT\\dataset\\SpecificationData\\MatchaEnglishWebsite\"\n",
    "# save_path = r\"D:\\Dissertation-GPT\\evaluate\\prove\\Matcha\\ts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase_name_list = []\n",
    "project_name = os.path.basename(usecase_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Add new topic', 'AddLesson', 'AddQuestion ', 'EditTest', 'Flashcard', 'Handbook', 'Learning days history', 'ListenToPronunciation', 'Login', 'Registry', 'Review test', 'WordSortingTest']\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(usecase_path):\n",
    "    usecase_name_list.append (filename.split(\".txt\")[0])\n",
    "print(usecase_name_list)\n",
    "usecase_name_list=[\"AddQuestion \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddQuestion \n",
      "gpt_response \n",
      "Based on the provided use case, here are the predicted scenarios:\n",
      "\n",
      "### Positive Test Scenario\n",
      "1. **Main Flow Scenario**: Admin successfully creates a question for the selection test by following the main flow steps from 1 to 15, ensuring all fields are validly filled, including a valid sentence with '...', a correct answer, and three different wrong answers, all under 250 characters and without any special characters.\n",
      "\n",
      "### Negative Test Scenarios\n",
      "#### Alternative Flow 2: Skip compulsory field \"sentence\"\n",
      "2. Admin attempts to save a question without filling the \"sentence\" field, leading to a notification prompting to fill the missing field.\n",
      "\n",
      "#### Alternative Flow 3: Skip compulsory field \"'correct answer\"\n",
      "3. Admin attempts to save a question without filling the \"correct answer\" field, leading to a notification prompting to fill the missing field.\n",
      "\n",
      "#### Alternative Flow 4: Skip compulsory field 'other option 1'\n",
      "4. Admin attempts to save a question without filling the \"other option 1\" field, leading to a notification prompting to fill the missing field.\n",
      "\n",
      "#### Alternative Flow 5: Skip compulsory field 'other option 2'\n",
      "5. Admin attempts to save a question without filling the \"other option 2\" field, leading to a notification prompting to fill the missing field.\n",
      "\n",
      "#### Alternative Flow 6: Skip compulsory field 'other option 3'\n",
      "6. Admin attempts to save a question without filling the \"other option 3\" field, leading to a notification prompting to fill the missing field.\n",
      "\n",
      "#### Alternative Flow 7: Admin chooses to cancel the question creation and chooses to stay\n",
      "7. Admin presses 'Cancel' during question creation, chooses 'Stay' when prompted, and then successfully saves the question.\n",
      "\n",
      "#### Alternative Flow 8: Admin enters invalid sentences\n",
      "8. Admin fills in an invalid sentence (e.g., over 250 characters, contains special characters) and attempts to save, leading to a notification about the invalid sentence.\n",
      "\n",
      "#### Exception Flow 1: Admin leaves without saving\n",
      "9. Admin navigates away from the question creation page using the browser's back button without saving, leading to no question being saved.\n",
      "\n",
      "#### Exception Flow 2: Admin cancels the question creation and confirms the cancellation\n",
      "10. Admin presses 'Cancel' during question creation and confirms the cancellation, leading to no question being saved and redirection to the \"Word Information\" page.\n",
      "\n",
      "Each of these scenarios tests a different path through the use case, ensuring that both the happy path (where everything goes right) and various edge cases (where something goes wrong) are covered.\n"
     ]
    }
   ],
   "source": [
    "for usecase_name in usecase_name_list:\n",
    "    print(usecase_name)\n",
    "    usecase_directlink = os.path.join(usecase_path,usecase_name+\".txt\")\n",
    "    prompt_all = read_file_content(usecase_directlink)\n",
    "    promptSYSTEM_PROMPT = [\n",
    "        { \"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        { \"role\": \"user\", \"content\": prompt_all}\n",
    "    ]\n",
    "    gpt_response = ask(promptSYSTEM_PROMPT, client, model)    \n",
    "    print(\"gpt_response \\n\" +gpt_response)\n",
    "    # write_string_to_file(os.path.join(save_path,f\"{usecase_name}.txt\"), gpt_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
