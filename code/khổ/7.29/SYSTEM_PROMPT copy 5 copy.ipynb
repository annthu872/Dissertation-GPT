{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "GPT_MODEL_4 = \"gpt-4-0125-preview\"\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "model = GPT_MODEL_4\n",
    "\n",
    "def ask(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def askJSON(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "      response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "def read_file_content(file_path):\n",
    "    # Detect the encoding\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "    \n",
    "    # Read the file with the detected encoding\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at path {file_path} was not found.\"\n",
    "    except UnicodeDecodeError:\n",
    "        return f\"Error: The file at path {file_path} cannot be decoded with the {encoding} encoding.\"\n",
    "    except IOError:\n",
    "        return f\"Error: An I/O error occurred while reading the file at path {file_path}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_string_to_file(filename, content):\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(content)\n",
    "        print(f\"String has been written to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Based on the provided use case specification, please generate a set of test scenarios to thoroughly test the functionality described in the use case.\n",
    "Your task is to generate suitable test scenarios that cover all the flows and test the boundaries of conditions, if possible. Each scenario should clearly and specifically describe the situation to be tested.\n",
    "Example for condition: \"a valid username must be over 8 characters and below 30 characters.\" When you meets something like this, make sure to treat each condition as a negative scenario seperately. That means you will have two negative scenario: invalid username with lower than 8 characters and invalid username with higher than 30 characters. \n",
    "Please ensure that your test scenarios cover both the main flow and any alternate flows mentioned in the use case specification. Also, consider potential exception flows to address errors, failures, or unexpected events that could occur during the execution of the use case and encompass negative test scenarios (including edge cases and invalid inputs), and unexpected user behaviors.\n",
    "Keep in mind the agile nature of the application and prioritize scenarios that align closely with the given use case specification and the application's requirements.\n",
    "Return the list of test scenarios name to test the use case\n",
    "Rules to predict scenarios:\n",
    "- Stay close to the details described in the flow.\n",
    "- Focus on important and likely scenarios, important scenario is the scenario that users are more likely to encounter it. \n",
    "- Minimize the appearance of rare scenarios. \n",
    "- If there is no other action in the flow beside clicking or there is no condition to vary the user's actions, that flow has one scenario only.\n",
    "- A scenario often refers to a specific sequence of events or user actions that could potentially lead to a change in how the application behaves or responds.\n",
    "- Test scenarios should be derived from cohesive sequences of steps that represent meaningful user interactions, rather than isolated steps.\n",
    "- Do not generate scenarios with user analysis. (Example: User accidentally do A and user intentionally do A is the same scenario, so do not consider about \"accidentally\" or \"intentionally\" in scenario)\n",
    "- You cannot separate parts of a flow to be a scenario (Example: predict multiple scenarios for a flow by dividing steps into parts) because each scenarios should be independent and require a complete flow to proceed.\n",
    "- A scenario should cover from the first step to the final step in the flow, the start or the result of the scenario could be different.\n",
    "- You cannot separate parts of a flow to be a scenario (Example: predict multiple scenarios for a flow by dividing steps into parts) because each scenarios should be independent and require a complete flow to proceed.\n",
    "- Do not arbitrarily create additional test scenarios to test cases that not mention in the use case flow.\n",
    "I only need scenarios's name for the output, I do not need the steps to go with it.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase_path = r\"D:\\Dissertation-GPT\\dataset\\SpecificationData\\MatchaEnglishWebsite\"\n",
    "# save_path = r\"D:\\Dissertation-GPT\\evaluate\\prove\\Matcha\\ts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase_name_list = []\n",
    "project_name = os.path.basename(usecase_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(usecase_path):\n",
    "#     usecase_name_list.append (filename.split(\".txt\")[0])\n",
    "# print(usecase_name_list)\n",
    "usecase_name_list=[\"AddQuestion  - Copy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddQuestion  - Copy\n",
      "gpt_response \n",
      "1. Create question with valid inputs\n",
      "2. Access Lesson Management from Homepage\n",
      "3. Skip compulsory field \"sentence\" and save\n",
      "4. Skip compulsory field \"correct answer\" and save\n",
      "5. Skip compulsory field \"other option 1\" and save\n",
      "6. Skip compulsory field \"other option 2\" and save\n",
      "7. Skip compulsory field \"other option 3\" and save\n",
      "8. Cancel question creation and choose to stay\n",
      "9. Enter invalid input for a field\n",
      "10. Leave page without saving by using browser back button\n",
      "11. Cancel question creation and confirm to cancel\n",
      "12. Create question with sentence exceeding 250 characters\n",
      "13. Create question with sentence containing special characters\n",
      "14. Create question with \"correct answer\" exceeding 100 characters\n",
      "15. Create question with \"correct answer\" containing invalid special characters\n",
      "16. Create question with \"other option 1\" exceeding 100 characters\n",
      "17. Create question with \"other option 1\" containing invalid special characters\n",
      "18. Create question with \"other option 2\" exceeding 100 characters\n",
      "19. Create question with \"other option 2\" containing invalid special characters\n",
      "20. Create question with \"other option 3\" exceeding 100 characters\n",
      "21. Create question with \"other option 3\" containing invalid special characters\n",
      "gpt_response \n",
      "1. Create question for selection test - Main flow\n",
      "2. Access Lesson Management from Homepage - Alternative flow 1\n",
      "3. Skip compulsory field \"sentence\" and save - Alternative flow 2\n",
      "4. Skip compulsory field \"correct answer\" and save - Alternative flow 3\n",
      "5. Skip compulsory field \"other option 1\" and save - Alternative flow 4\n",
      "6. Skip compulsory field \"other option 2\" and save - Alternative flow 5\n",
      "7. Skip compulsory field \"other option 3\" and save - Alternative flow 6\n",
      "8. Cancel question creation and choose to stay - Alternative flow 7\n",
      "9. Enter invalid field and save - Alternative flow 8\n",
      "10. Leave page without saving question - Exception flow 1\n",
      "11. Cancel question creation and confirm cancellation - Exception flow 2\n",
      "gpt_response \n",
      "1. Create question for selection test successfully\n",
      "2. Access Lesson Management page from Homepage\n",
      "3. Skip compulsory field \"sentence\" and save question\n",
      "4. Skip compulsory field \"correct answer\" and save question\n",
      "5. Skip compulsory field \"other option 1\" and save question\n",
      "6. Skip compulsory field \"other option 2\" and save question\n",
      "7. Skip compulsory field \"other option 3\" and save question\n",
      "8. Cancel question creation and choose to stay\n",
      "9. Enter invalid input in a field and save question\n",
      "10. Leave question creation by browser back button without saving\n",
      "11. Cancel question creation and confirm to cancel\n"
     ]
    }
   ],
   "source": [
    "for usecase_name in usecase_name_list:\n",
    "    print(usecase_name)\n",
    "    usecase_directlink = os.path.join(usecase_path,usecase_name+\".txt\")\n",
    "    prompt_all = read_file_content(usecase_directlink)\n",
    "    promptSYSTEM_PROMPT = [\n",
    "        { \"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        { \"role\": \"user\", \"content\": prompt_all}\n",
    "    ]\n",
    "    gpt_response = ask(promptSYSTEM_PROMPT, client, model)    \n",
    "    print(\"gpt_response \\n\" +gpt_response)\n",
    "\n",
    "    prompt_all = read_file_content(usecase_directlink)\n",
    "    promptSYSTEM_PROMPT = [\n",
    "        { \"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        { \"role\": \"user\", \"content\": prompt_all}\n",
    "    ]\n",
    "    gpt_response = ask(promptSYSTEM_PROMPT, client, model)    \n",
    "    print(\"gpt_response \\n\" +gpt_response)\n",
    "\n",
    "    prompt_all = read_file_content(usecase_directlink)\n",
    "    promptSYSTEM_PROMPT = [\n",
    "        { \"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        { \"role\": \"user\", \"content\": prompt_all}\n",
    "    ]\n",
    "    gpt_response = ask(promptSYSTEM_PROMPT, client, model)    \n",
    "    print(\"gpt_response \\n\" +gpt_response)\n",
    "    # write_string_to_file(os.path.join(save_path,f\"{usecase_name}.txt\"), gpt_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
