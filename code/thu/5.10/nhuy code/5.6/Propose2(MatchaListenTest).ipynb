{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "GPT_MODEL_4 = \"gpt-4-0125-preview\"\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "model = GPT_MODEL_4\n",
    "\n",
    "def ask(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt\n",
    "MAIN_FLOW_SYSTEM_PROMPT=\"\"\"\n",
    "I want you to act as software tester.\n",
    "Your task is to read this information about one main flow of a use case.\n",
    "Then you predict all scenarios that can happen in this flow.\n",
    "\n",
    "Rules to predict scenarios:\n",
    "- Stay close to the details described in the flow.\n",
    "- Choose important cases to generate, important scenario is the scenario that users are more likely to encounter it.\n",
    "- Limit the appearance of scenarios that are hard to happen. \n",
    "- A scenario encompasses a whole function, not just verifying individual steps.\n",
    "- If there is no other action in the flow beside clicking or there is no condition to vary the user's actions, that flow has one scenario only.\n",
    "- A scenario often refers to a specific sequence of events or user actions that could potentially lead to a change in how the application behaves or responds.\n",
    "- Test scenarios should be derived from cohesive sequences of steps that represent meaningful user interactions, rather than isolated steps.\n",
    "- A scenario should cover from the first step to the final step in the flow, the start or the result of the scenario could be different.\n",
    "- You cannot separate parts of a flow to be a scenario (Example: predict multiple scenarios for a flow by dividing steps into parts) because each scenarios should be independent and require a complete flow to proceed.\n",
    "I only need scenarios's name for the output, I do not need the steps to go with it.\n",
    "\"\"\"\n",
    "\n",
    "SUB_FLOW_SYSTEM_PROMPT=\"\"\"\n",
    "I want you to act as software tester.\n",
    "Your task is to read this information about one main flow and one alternative or exception flow of a use case.\n",
    "Then you predict all scenarios that can lead user from the main flow to change to the alternative or exception flow mentioned for creating test cases.\n",
    "\n",
    "Rules to predict scenarios:\n",
    "- A scenario encompasses a whole function, not just verifying individual steps.\n",
    "- If there is no other action in the flow beside clicking or there is no condition to vary the user's actions, that flow has one scenario only.\n",
    "- A scenario often refers to a specific sequence of events or user actions that could potentially lead to a change in how the application behaves or responds.\n",
    "- Test scenarios should be derived from cohesive sequences of steps that represent meaningful user interactions, rather than isolated steps.\n",
    "- A scenario should cover from the first step to the final step in the flow, the start or the result of the scenario could be different.\n",
    "- You cannot separate parts of a flow to be a scenario (Example: predict multiple scenarios for a flow by dividing steps into parts) because each scenarios should be independent and require a complete flow to proceed.\n",
    "- Do not generate scenarios with user analysis. (Example: User accidentally do A and user intentionally do A is the same scenario, so do not consider about \"accidentally\" or \"intentionally\" in scenario)\n",
    "- Do not choose another option that is not chosen by the flow, eventhough it is mentioned (Example: A pop up with OK and Cancel, the flow only has step choose OK. Do not generate scenario that press Cancel)\n",
    "- Do not generate scenario to test only the main flow.\n",
    "I only need scenarios's name for the output, I do not need the steps to go with it.\n",
    "\"\"\"\n",
    "\n",
    "FILTER_SYSTEM_PROMPT=\"\"\"\n",
    "Your task is to read all of this scenarios generation from many sources.\n",
    "Then you remove all the same copies because there are many duplicate scenarios in meanings inside the input.\n",
    "Make sure every scenarios in the response is unique.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_flow_prompt=\"\"\"\n",
    "Step 1: The screen displays the test with a speaker button. \n",
    "Step 2: Learner can guess the entire word and choose answer.\n",
    "Step 3: The system compares Vietnamese meanings and English vocabulary that the user chooses.\n",
    "Step 4: If the answer is correct, the pop up screen is green.\n",
    "\"\"\"\n",
    "\n",
    "alt_prompt_1=\"\"\"\n",
    "basic flow:\n",
    "Step 1: The screen displays the test with a speaker button. \n",
    "Step 2: Learner can guess the entire word and choose answer.\n",
    "Step 3: The system compares Vietnamese meanings and English vocabulary that the user chooses.\n",
    "Step 4: If the answer is correct, the pop up screen is green.\n",
    "\n",
    "Alternative flow: Learner chooses wrong answer\n",
    "At step 4 of basic flow: If the answer is wrong, the pop up screen is red.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Scenario: Learner views continuous learning days without breaking the chain.\n",
      "2. Scenario: Learner views learning days after breaking the chain.\n"
     ]
    }
   ],
   "source": [
    "promptMainScenario = [\n",
    "    { \"role\": \"system\", \"content\": MAIN_FLOW_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": main_flow_prompt}\n",
    "  ]\n",
    "main_gpt_response = ask(promptMainScenario, client, model)\n",
    "\n",
    "promptAlt = [\n",
    "    { \"role\": \"system\", \"content\": SUB_FLOW_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": alt_prompt_1}\n",
    "  ]\n",
    "alt_gpt_response = ask(promptAlt, client, model)\n",
    "\n",
    "filtercontent = main_gpt_response + alt_gpt_response\n",
    "\n",
    "promptFilter = [\n",
    "    { \"role\": \"system\", \"content\": FILTER_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": filtercontent}\n",
    "  ]\n",
    "filter_gpt_response = ask(promptFilter, client, model)\n",
    "print(filter_gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Scenario: Learner views continuous learning days without breaking the chain.\n",
      "2. Scenario: Learner views learning days after breaking the chain.\n"
     ]
    }
   ],
   "source": [
    "print(main_gpt_response)\n",
    "print(alt_gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Successful Display of Continuous Learning Days\n",
      "2. Display After Breaking the Learning Chain\n"
     ]
    }
   ],
   "source": [
    "promptMainScenario = [\n",
    "    { \"role\": \"system\", \"content\": MAIN_FLOW_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": main_flow_prompt}\n",
    "  ]\n",
    "main_gpt_response = ask(promptMainScenario, client, model)\n",
    "\n",
    "promptAlt = [\n",
    "    { \"role\": \"system\", \"content\": SUB_FLOW_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": alt_prompt_1}\n",
    "  ]\n",
    "alt_gpt_response = ask(promptAlt, client, model)\n",
    "\n",
    "filtercontent = main_gpt_response + alt_gpt_response\n",
    "\n",
    "promptFilter = [\n",
    "    { \"role\": \"system\", \"content\": FILTER_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": filtercontent}\n",
    "  ]\n",
    "filter_gpt_response = ask(promptFilter, client, model)\n",
    "print(filter_gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Successful Display of Continuous Learning Days\n",
      "2. Display After Breaking the Learning Chain\n"
     ]
    }
   ],
   "source": [
    "print(main_gpt_response)\n",
    "print(alt_gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Scenario: Learner views continuous learning days without breaking the chain.\n",
      "2. Scenario: Learner views learning days after breaking the chain.\n"
     ]
    }
   ],
   "source": [
    "promptMainScenario = [\n",
    "    { \"role\": \"system\", \"content\": MAIN_FLOW_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": main_flow_prompt}\n",
    "  ]\n",
    "main_gpt_response = ask(promptMainScenario, client, model)\n",
    "\n",
    "promptAlt = [\n",
    "    { \"role\": \"system\", \"content\": SUB_FLOW_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": alt_prompt_1}\n",
    "  ]\n",
    "alt_gpt_response = ask(promptAlt, client, model)\n",
    "\n",
    "filtercontent = main_gpt_response + alt_gpt_response\n",
    "\n",
    "promptFilter = [\n",
    "    { \"role\": \"system\", \"content\": FILTER_SYSTEM_PROMPT},\n",
    "    { \"role\": \"user\", \"content\": filtercontent}\n",
    "  ]\n",
    "filter_gpt_response = ask(promptFilter, client, model)\n",
    "print(filter_gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Scenario: Learner views continuous learning days without breaking the chain.\n",
      "2. Scenario: Learner views learning days after breaking the chain.\n"
     ]
    }
   ],
   "source": [
    "print(main_gpt_response)\n",
    "print(alt_gpt_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
