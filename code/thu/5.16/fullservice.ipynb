{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_summary_files(directory, path):\n",
    "    # Define the names of the summary files\n",
    "    directory_name = os.path.basename(directory)\n",
    "    summary_file_raw = os.path.join(path, f\"{directory_name}-Raw.txt\")\n",
    "    summary_file = os.path.join(path, f\"{directory_name}.txt\")\n",
    "\n",
    "    # Initialize strings to store file contents\n",
    "    raw_content = \"\"\n",
    "    non_raw_content = \"\"\n",
    "\n",
    "    # Iterate through the files in the directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        # Check if the current item is a file and not one of the summary files\n",
    "        if os.path.isfile(file_path) and file_name not in [os.path.basename(summary_file_raw), os.path.basename(summary_file)]:\n",
    "            # Read the file content\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "                print(content)\n",
    "                if \"-Raw\" in file_name:\n",
    "                    raw_content += \"Scenario: \"+ file_name +\"\\n\"\n",
    "                    raw_content += content + \"\\n\"\n",
    "                else:\n",
    "                    non_raw_content +=\"Scenario: \"+ file_name +\"\\n\"\n",
    "                    non_raw_content += content + \"\\n\"\n",
    "\n",
    "    # Write the collected raw file contents to \"Summary File Raw.txt\"\n",
    "    with open(summary_file_raw, 'w') as file:\n",
    "        file.write(raw_content)\n",
    "\n",
    "    # Write the collected non-raw file contents to \"Summary File.txt\"\n",
    "    with open(summary_file, 'w') as file:\n",
    "        file.write(non_raw_content)\n",
    "\n",
    "# Example usage\n",
    "directory_path =r\"D:\\Dissertation-GPT\\5.25-NhuY\\Matcha\\AddLesson\"  # Replace with your folder path\n",
    "path = r\"D:\\Dissertation-GPT\\5.25-NhuY\\Matcha\\summary test case\"\n",
    "create_summary_files(directory_path, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_testcase_file(file_content,filename):\n",
    "    with open(file_content, 'r') as file:\n",
    "        content = file.read()\n",
    "    scenarios = content.strip().split('Scenario: ')\n",
    "    scenarios = [s for s in scenarios if s.strip()]  # Remove empty strings if any\n",
    "\n",
    "    # Function to parse each scenario into a dictionary\n",
    "    def parse_scenario(scenario_text):\n",
    "        lines = scenario_text.strip().split('\\n')\n",
    "        scenario_name = lines[0].strip()        \n",
    "        test_cases = []\n",
    "        new_string = '\\n'.join(lines[1:])\n",
    "        testcase = new_string.strip().split('Test Case: ')\n",
    "        print(testcase)\n",
    "        for i in testcase:\n",
    "            lines = i.strip().split('\\n')\n",
    "            test_case = {}\n",
    "            for line in lines[1:]:\n",
    "                if line.startswith('testSteps:'):\n",
    "                    test_case['testSteps'] = []\n",
    "                    continue\n",
    "                if line.startswith('  - Step '):\n",
    "                    test_case['testSteps'].append(line.strip())\n",
    "                    continue\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    test_case[key.strip()] = value.strip()\n",
    "            test_cases.append(test_case)\n",
    "            # print(scenario_name, test_case)\n",
    "        return scenario_name, test_cases\n",
    "\n",
    "    # Parse all scenarios\n",
    "    parsed_scenarios = {}\n",
    "    for scenario in scenarios:\n",
    "        name, details = parse_scenario(scenario)\n",
    "        for i in range(len(details)):\n",
    "            str_num = str(i)\n",
    "            element_name = name + str_num\n",
    "            parsed_scenarios[element_name] = details[i]\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(parsed_scenarios, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_excel_with_json_testcase_data(json_file, excel_file):\n",
    "    # Load JSON data\n",
    "    with open(json_file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    # Load Excel file\n",
    "    df = pd.read_excel(excel_file)\n",
    "    \n",
    "    # Iterate through each row in the Excel file\n",
    "    for index, row in df.iterrows():\n",
    "        testcase_name = row['Test Case Name']  # Assuming column A is named 'Scenario Name'\n",
    "        print(testcase_name)\n",
    "\n",
    "        # Search for the scenario name in the JSON data\n",
    "        for key, value in json_data.items():\n",
    "            if value.get(\"testCaseName\") == testcase_name:\n",
    "                print(value)\n",
    "                test_steps = json_data[key].get('testSteps', [])\n",
    "                expected_result = json_data[key].get('expectedResult', \"\")\n",
    "                objective = json_data[key].get('objective', [])\n",
    "                test_step_str =  '\\n'.join(test_steps)\n",
    "                combined_info = (\n",
    "                        f\"Test Case Name: {testcase_name}\\n\"\n",
    "                        f\"Objective: {objective}\\n\"\n",
    "                        f\"Test Steps: { test_step_str}\\n\"\n",
    "                        f\"Expected Result: {expected_result}\"\n",
    "                )\n",
    "                # Update the corresponding cells in the DataFrame\n",
    "                df.at[index, 'Test Case'] = combined_info\n",
    "                df.at[index, 'Test Steps'] = test_step_str  # Assuming column B is named 'Test Steps'\n",
    "                df.at[index, 'Expected Result'] = expected_result  # Assuming column C is named 'Expected Result'\n",
    "                df.at[index, 'Objective'] = objective\n",
    "                continue\n",
    "    # Save the updated DataFrame to a new Excel file\n",
    "    df.to_excel(excel_file, index=False)\n",
    "\n",
    "# Define file paths\n",
    "\n",
    "# Call the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory =r\"D:\\Dissertation-GPT\\5.25-NhuY\\Matcha\"  # Replace with your folder path\n",
    "directory_name = [\"AddLesson\"]\n",
    "path= r\"D:\\Dissertation-GPT\\5.25-NhuY\\Matcha\\summary test case\"\n",
    "create_summary_files(os.path.join(directory,directory_name[0]), path)\n",
    "create_json_testcase_file(os.path.join(path,directory_name[0])+\".txt\",os.path.join(path,directory_name[0])+\".json\")\n",
    "create_json_testcase_file(os.path.join(path,directory_name[0])+\"-Raw.txt\",os.path.join(path,directory_name[0])+\"-Raw.json\")\n",
    "\n",
    "usecase= \"AddLesson\"\n",
    "json_file = os.path.join(path,usecase)+\"-Raw.json\"\n",
    "excel_file = r\"D:\\Dissertation-GPT\\code\\thu\\5.16\\output.xlsx\"\n",
    "\n",
    "update_excel_with_json_testcase_data(json_file, excel_file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
