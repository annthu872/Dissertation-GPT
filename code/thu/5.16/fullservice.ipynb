{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_summary_files(directory, save_path):\n",
    "    # Define the names of the summary files\n",
    "    directory_name = os.path.basename(directory)\n",
    "    summary_file_raw = os.path.join(save_path, f\"{directory_name}-Raw.txt\")\n",
    "    summary_file = os.path.join(save_path, f\"{directory_name}.txt\")\n",
    "\n",
    "    # Initialize strings to store file contents\n",
    "    raw_content = \"\"\n",
    "    non_raw_content = \"\"\n",
    "\n",
    "    # Iterate through the files in the directory\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        # Check if the current item is a file and not one of the summary files\n",
    "        if os.path.isfile(file_path) and file_name not in [os.path.basename(summary_file_raw), os.path.basename(summary_file)]:\n",
    "            # Read the file content\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "\n",
    "                content = file.read()\n",
    "                if \"-Raw\" in file_name:\n",
    "                    raw_content += \"Scenario: \"+ file_name +\"\\n\"\n",
    "                    raw_content += content + \"\\n\"\n",
    "                else:\n",
    "                    non_raw_content +=\"Scenario: \"+ file_name +\"\\n\"\n",
    "                    non_raw_content += content + \"\\n\"\n",
    "\n",
    "    # # Write the collected raw file contents to \"Summary File Raw.txt\"\n",
    "    # with open(summary_file_raw, 'w') as file:\n",
    "    #     file.write(raw_content)\n",
    "\n",
    "    # Write the collected non-raw file contents to \"Summary File.txt\"\n",
    "    with open(summary_file, 'w') as file:\n",
    "        file.write(non_raw_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_testcase_file(file_content,filename):\n",
    "    with open(file_content, 'r') as file:\n",
    "        content = file.read()\n",
    "    scenarios = content.strip().split('Scenario: ')\n",
    "    scenarios = [s for s in scenarios if s.strip()]  # Remove empty strings if any\n",
    "\n",
    "    # Function to parse each scenario into a dictionary\n",
    "    def parse_scenario(scenario_text):\n",
    "        lines = scenario_text.strip().split('\\n')\n",
    "        scenario_name = lines[0].strip()        \n",
    "        test_cases = []\n",
    "        new_string = '\\n'.join(lines[1:])\n",
    "        testcase = new_string.strip().split('Test Case: ')\n",
    "        for i in testcase:\n",
    "            lines = i.strip().split('\\n')\n",
    "            test_case = {}\n",
    "            for line in lines[1:]:\n",
    "                if line.startswith('testSteps:'):\n",
    "                    test_case['testSteps'] = []\n",
    "                    continue\n",
    "                if line.startswith('  - Step '):\n",
    "                    test_case['testSteps'].append(line.strip())\n",
    "                    continue\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    test_case[key.strip()] = value.strip()\n",
    "            test_cases.append(test_case)\n",
    "        return scenario_name, test_cases\n",
    "\n",
    "    # Parse all scenarios\n",
    "    parsed_scenarios = {}\n",
    "    for scenario in scenarios:\n",
    "        name, details = parse_scenario(scenario)\n",
    "        for i in range(len(details)):\n",
    "            str_num = str(i)\n",
    "            element_name = name + str_num\n",
    "            parsed_scenarios[element_name] = details[i]\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(parsed_scenarios, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_excel_with_json_testcase_data(json_file, excel_file):\n",
    "    # Load JSON data\n",
    "    with open(json_file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    # Load Excel file\n",
    "    df = pd.read_excel(excel_file)\n",
    "    \n",
    "    # Iterate through each row in the Excel file\n",
    "    for index, row in df.iterrows():\n",
    "        testcase_name = row['Test Case Name']  # Assuming column A is named 'Scenario Name'\n",
    "        # Search for the scenario name in the JSON data\n",
    "        for key, value in json_data.items():\n",
    "            if value.get(\"testCaseName\") == testcase_name:\n",
    "                test_steps = json_data[key].get('testSteps', [])\n",
    "                expected_result = json_data[key].get('expectedResult', \"\")\n",
    "                objective = json_data[key].get('objective', [])\n",
    "                test_step_str =  '\\n'.join(test_steps)\n",
    "                # combined_info = (\n",
    "                #         f\"Test Case Name: {testcase_name}\\n\"\n",
    "                #         f\"Objective: {objective}\\n\"\n",
    "                #         f\"Test Steps: { test_step_str}\\n\"\n",
    "                #         f\"Expected Result: {expected_result}\"\n",
    "                # )\n",
    "                # Update the corresponding cells in the DataFrame\n",
    "                # df.at[index, 'Test Case'] = combined_info\n",
    "                df.at[index, 'Test Steps'] = test_step_str  # Assuming column B is named 'Test Steps'\n",
    "                df.at[index, 'Expected Result'] = expected_result  # Assuming column C is named 'Expected Result'\n",
    "                df.at[index, 'Objective'] = objective\n",
    "                continue\n",
    "    # Save the updated DataFrame to a new Excel file\n",
    "    df.to_excel(excel_file, index=False)\n",
    "\n",
    "# Define file paths\n",
    "\n",
    "# Call the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_directories(directory_path):\n",
    "    directories = []\n",
    "    # Check if the directory exists\n",
    "    if os.path.exists(directory_path):\n",
    "        # Iterate over all items in the directory\n",
    "        for item in os.listdir(directory_path):\n",
    "            # Join the directory path with the item name\n",
    "            item_path = os.path.join(directory_path, item)\n",
    "            # Check if the item is a directory and add it to the list\n",
    "            if os.path.isdir(item_path):\n",
    "                directories.append(item)\n",
    "    else:\n",
    "        print(\"Directory does not exist.\")\n",
    "    return directories\n",
    "\n",
    "# Example usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Dissertation-GPT\\\\evaluate\\\\ResultSet\\\\6.24\\\\shopee - best\\\\tc\\\\shopee\\\\Buy.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDissertation-GPT\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mResultSet\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m6.24\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mshopee - best\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m directory_name:\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mcreate_summary_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mapplication\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mapplication\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     create_json_testcase_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path,application,i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path,application,i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 32\u001b[0m, in \u001b[0;36mcreate_summary_files\u001b[1;34m(directory, save_path)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 non_raw_content \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m content \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# # Write the collected raw file contents to \"Summary File Raw.txt\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# with open(summary_file_raw, 'w') as file:\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#     file.write(raw_content)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Write the collected non-raw file contents to \"Summary File.txt\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msummary_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     33\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(non_raw_content)\n",
      "File \u001b[1;32me:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Dissertation-GPT\\\\evaluate\\\\ResultSet\\\\6.24\\\\shopee - best\\\\tc\\\\shopee\\\\Buy.txt'"
     ]
    }
   ],
   "source": [
    "application = \"shopee\"\n",
    "directory =r\"D:\\Dissertation-GPT\\5.25-NhuY\"  # Replace with your folder path\n",
    "directory_name = list_directories(os.path.join(directory,application))\n",
    "path = r\"D:\\Dissertation-GPT\\evaluate\\ResultSet\\6.24\\shopee - best\\tc\"\n",
    "for i in directory_name:\n",
    "    create_summary_files(os.path.join(directory,application,i), os.path.join(path,application))\n",
    "    create_json_testcase_file(os.path.join(path,application,i)+\".txt\",os.path.join(path,application,i)+\".json\")\n",
    "    # create_json_testcase_file(os.path.join(path,application,i)+\"-Raw.txt\",os.path.join(path,application,i)+\"-Raw.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in directory_name:\n",
    "\n",
    "#     json_file = os.path.join(path,application,i)+\".json\" #nhớ đổi raw nếu có\n",
    "#     excel_file = r\"D:\\Dissertation-GPT\\code\\thu\\5.16\\output.xlsx\"\n",
    "\n",
    "#     update_excel_with_json_testcase_data(json_file, excel_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
