{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "GPT_MODEL_4 = \"gpt-4-0125-preview\"\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "model = GPT_MODEL_4\n",
    "\n",
    "def ask(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def askJSON(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "      response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_string_to_file(filename, content):\n",
    "    try:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(content)\n",
    "        print(f\"String has been written to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "def read_file_content(file_path):\n",
    "    # Detect the encoding\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "    \n",
    "    # Read the file with the detected encoding\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at path {file_path} was not found.\"\n",
    "    except UnicodeDecodeError:\n",
    "        return f\"Error: The file at path {file_path} cannot be decoded with the {encoding} encoding.\"\n",
    "    except IOError:\n",
    "        return f\"Error: An I/O error occurred while reading the file at path {file_path}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case_list = [\n",
    "    \"Add new topic.txt\",\n",
    "\"AddLesson.txt\",\n",
    "\"AddQuestion .txt\",\n",
    "\"EditTest.txt\",\n",
    "\"Handbook.txt\",\n",
    "\"Learning days history.txt\",\n",
    "\"ListenToPronunciation.txt\",\n",
    "\"Review test.txt\",\n",
    "\"WordSortingTest.txt\",\n",
    "\"Flashcard.txt\",\n",
    "\"Login.txt\",\n",
    "\"Registry.txt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case_list= [\n",
    "\"Add a new author.txt\",\n",
    "\"Add a new book.txt\",\n",
    "\"Add a new genre.txt\",\n",
    "\"Display author details.txt\",\n",
    "\"Display genre details.txt\",\n",
    "\"Display the list of authors.txt\",\n",
    "\"Display the list of books.txt\",\n",
    "\"Display the list of genres.txt\",\n",
    "\"Edit the author.txt\",\n",
    "\"Edit the book.txt\",\n",
    "\"Edit the genre.txt\",\n",
    "\"Remove the author.txt\",\n",
    "\"Remove the genre.txt\",\n",
    "\"Display book details.txt\",\n",
    "\"Remove the book.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_case_directory_path = r\"D:\\GPT-testing\\SpecificationData\\MatchaEnglishWebsite\"\n",
    "# # test_scenario_directory_path = r\"D:\\Dissertation-GPT\\evaluate\\baseline\\ts\\matcha\"\n",
    "# save_testscenario_path = r\"D:\\Dissertation-GPT\\evaluate\\baseline 2\\matcha\\ts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case_directory_path = r\"D:\\GPT-testing\\SpecificationData\\Book(Github)\"\n",
    "save_testscenario_path = r\"D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_GENERATE_SCENARIO = \"\"\"\n",
    "Generate test scenarios for me based on this use case description.\n",
    "Give me only name of test scenarios.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add a new author\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Add a new author.txt\n",
      "Add a new book\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Add a new book.txt\n",
      "Add a new genre\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Add a new genre.txt\n",
      "Display author details\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Display author details.txt\n",
      "Display genre details\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Display genre details.txt\n",
      "Display the list of authors\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Display the list of authors.txt\n",
      "Display the list of books\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Display the list of books.txt\n",
      "Display the list of genres\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Display the list of genres.txt\n",
      "Edit the author\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Edit the author.txt\n",
      "Edit the book\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Edit the book.txt\n",
      "Edit the genre\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Edit the genre.txt\n",
      "Remove the author\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Remove the author.txt\n",
      "Remove the genre\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Remove the genre.txt\n",
      "Display book details\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Display book details.txt\n",
      "Remove the book\n",
      "String has been written to D:\\Dissertation-GPT\\evaluate\\baseline 2\\book\\ts\\Remove the book.txt\n"
     ]
    }
   ],
   "source": [
    "for usecase in use_case_list:\n",
    "    base_name = os.path.basename(usecase)\n",
    "    usecase_name = os.path.splitext(base_name)[0]\n",
    "    usecase_path = os.path.join (use_case_directory_path,f\"{usecase_name}.txt\" )\n",
    "    file_content = read_file_content(usecase_path)\n",
    "\n",
    "    base_name = os.path.basename(usecase_path)\n",
    "    usecase_name = os.path.splitext(base_name)[0]\n",
    "    print(usecase_name)\n",
    "    # usecase = \"Use case: \"+ read_file_content(usecase_path)\n",
    "    promptExtractCondition = [\n",
    "      { \"role\": \"system\", \"content\": BASELINE_GENERATE_SCENARIO},\n",
    "      { \"role\": \"user\", \"content\": file_content}\n",
    "    ]\n",
    "    testscenario_path = os.path.join (save_testscenario_path,f\"{usecase_name}.txt\" )\n",
    "\n",
    "    gpt_response = ask(promptExtractCondition, client, model)\n",
    "    write_string_to_file(testscenario_path,gpt_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_content = read_file_content(use_case_list[0])\n",
    "# if( file_content not in \"None\"):\n",
    "#   promptExtractCondition = [\n",
    "#       { \"role\": \"system\", \"content\": BASELINE_GENERATE_SCENARIO1},\n",
    "#       { \"role\": \"user\", \"content\": file_content}\n",
    "#     ]\n",
    "#   gpt_response = ask(promptExtractCondition, client, model)\n",
    "#   print(gpt_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_content = read_file_content(use_case_list[0])\n",
    "# if( file_content not in \"None\"):\n",
    "#   promptExtractCondition = [\n",
    "#       { \"role\": \"system\", \"content\": BASELINE_GENERATE_SCENARIO2},\n",
    "#       { \"role\": \"user\", \"content\": file_content}\n",
    "#     ]\n",
    "#   gpt_response = ask(promptExtractCondition, client, model)\n",
    "#   print(gpt_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
