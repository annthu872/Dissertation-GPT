{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "GPT_MODEL_4 = \"gpt-4-0125-preview\"\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "model = GPT_MODEL_4\n",
    "\n",
    "def ask(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def askJSON(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "      response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_string_to_file(filename, content):\n",
    "    try:\n",
    "        with open(filename, 'a') as file:\n",
    "            file.write(content)\n",
    "        print(f\"String has been written to {filename}\")\n",
    "    except IOError as e:\n",
    "        print(f\"An error occurred while writing to the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_to_list(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "def read_file_content(file_path):\n",
    "    # Detect the encoding\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "    \n",
    "    # Read the file with the detected encoding\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding=encoding) as file:\n",
    "            content = file.read()\n",
    "        return content\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: The file at path {file_path} was not found.\"\n",
    "    except UnicodeDecodeError:\n",
    "        return f\"Error: The file at path {file_path} cannot be decoded with the {encoding} encoding.\"\n",
    "    except IOError:\n",
    "        return f\"Error: An I/O error occurred while reading the file at path {file_path}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_to_txt_raw(json_data, file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for test_case, details in json_data.items():\n",
    "            file.write(f\"Test Case: {test_case}\\n\")\n",
    "            for key, value in details.items():\n",
    "                if isinstance(value, list):\n",
    "                    file.write(f\"{key}:\\n\")\n",
    "                    for item in value:\n",
    "                        file.write(f\"  - {item}\\n\")\n",
    "                else:\n",
    "                    file.write(f\"{key}: {value}\\n\")\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json_to_txt(json_data, file_name):\n",
    "    filtered_data = {k: v for k, v in json_data.items() if v.get(\"reflect\") == \"yes\"}\n",
    "    with open(file_name, 'w') as file:\n",
    "        for test_case, details in filtered_data.items():\n",
    "            file.write(f\"Test Case: {test_case}\\n\")\n",
    "            for key, value in details.items():\n",
    "                if isinstance(value, list):\n",
    "                    file.write(f\"{key}:\\n\")\n",
    "                    for item in value:\n",
    "                        file.write(f\"  - {item}\\n\")\n",
    "                else:\n",
    "                    file.write(f\"{key}: {value}\\n\")\n",
    "            file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_8=\"\"\"\n",
    "I want you to act as a software tester.\n",
    "Your task is to read the test scenario's name and the corresponding use case specification to base on those information for generateing test steps for test cases and their following expected result.\n",
    "Return the test cases in json format.\n",
    "The JSON format should follow the following structure:\n",
    "{\n",
    "  \"Test Case 1\":{\n",
    "    \"testCaseName\": \"Clear name of the test case so tester know what to test when they first read\",\n",
    "    \"objective\": \"Verify who doing what action or function in the test case and the summary of the final result of the test case\",\n",
    "    \"testSteps\": [\n",
    "      \"Step 1: Describe the step.\",\n",
    "      \"Step 2: Describe the step.\",\n",
    "      \"Step 3: Describe the step.\"\n",
    "    ],\n",
    "    \"expectedResult\": \"You inform the tester what should they see after doing all the steps\",\n",
    "    \"explanation\": \"Why do you create this test case? How does this test case related to the test scenario inputed?\",\n",
    "  },\n",
    "}\n",
    "If there are more than one test case for this scenario, continue writing other test case in this form.\n",
    "\n",
    "Rules for generating test steps:\n",
    "- Describe the test step clearly to make sure each test case is independent, tester do not need to read other information (example: other test case, use case specification) to know how to do that step.\n",
    "- Avoid references to other test cases or instructions like \"do as mentioned.\"\n",
    "- If the test case need to be repeated to test with different order, data or case, seperate them to be distinct test cases.\n",
    "- If the scenario is about testing the displation and there is no flow directly cover that scenario, use only the basic (or main) flow to test it.\n",
    "- If there are use cases mentioned in extended or included use case, create test case combine use cases, Try to find the connection point of use cases for combination. \n",
    "- For test scenarios mentioning navigation in the name, only produce test cases related to the specified navigation method. \n",
    "(Example: \"Scenario: User navigates to a page by navbar\", only produce a test case of user navigates to that page by navbar even though the use case description has many way to navigate to that page)\n",
    "- For test scenarios not mentioning navigation in the name, do not include any navigation test cases.\n",
    "- Generate test cases that directly match the scenario name. Choose only one flow to cover the scenario.\n",
    "- Ensure all actions and objectives match the scenario name.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELF_REF=\"\"\"\n",
    "Given a test scenario and test cases to test that given test scenario.\n",
    "Mark if test case can test the given test scenario or not through test steps, expected output, objective (although if it test other use case path or flow, if it is not used to test the given test scenario.)\n",
    "And give explanation why you think the resulted test case reflect the given test scenario or not. \n",
    "Your response should keep the format of the inserted test cases.\n",
    "The JSON format should follow the following structure:\n",
    "{\n",
    "  \"Test Case 1\":{\n",
    "    \"testCaseName\": \"Clear name of the test case so tester know what to test when they first read\",\n",
    "    \"objective\": \"Verify who doing what action or function in the test case and the summary of the final result of the test case\",\n",
    "    \"testSteps\": [\n",
    "      \"Step 1: Describe the step.\",\n",
    "      \"Step 2: Describe the step.\",\n",
    "      \"Step 3: Describe the step.\"\n",
    "    ],\n",
    "    \"expectedResult\": \"You inform the tester what should they see after doing all the steps\",\n",
    "    \"reflect\": \"yes/no\",\n",
    "    \"explanation\": \"explain why you think this test case reflect the given test scenario or not\",\n",
    "  },\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Add new topic', 'AddLesson', 'AddQuestion ', 'EditTest', 'Flashcard', 'Handbook', 'Learning days history', 'ListenToPronunciation', 'Login', 'Registry', 'Review test', 'WordSortingTest']\n"
     ]
    }
   ],
   "source": [
    "use_case_directory_path = r\"D:\\Dissertation-GPT\\dataset\\SpecificationData\\MatchaEnglishWebsite\"\n",
    "usecase_name_list = []\n",
    "project_name = \"English Learning Website\"\n",
    "for filename in os.listdir(use_case_directory_path):\n",
    "    usecase_name_list.append (filename.split(\".txt\")[0])\n",
    "print(usecase_name_list)\n",
    "\n",
    "test_scenario_directory_path = r\"D:\\Dissertation-GPT\\evaluate\\bestScenario\\MatchaEnglishWebsite\"\n",
    "save_testcase_path = r\"D:\\Dissertation-GPT\\evaluate\\bestScenario\\MatchaEnglishWebsite\\bestTCs\\Matcha\"\n",
    "save_testcase_raw_path = r\"D:\\Dissertation-GPT\\evaluate\\bestScenario\\MatchaEnglishWebsite\\bestTCs\\Matcha\\raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Dissertation-GPT\\\\evaluate\\\\bestScenario\\\\MatchaEnglishWebsite\\\\Add new topic.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m usecase_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin (use_case_directory_path,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musecase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n\u001b[0;32m      5\u001b[0m testscenario_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin (test_scenario_directory_path,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musecase_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n\u001b[1;32m----> 6\u001b[0m testscenario_list \u001b[38;5;241m=\u001b[39m \u001b[43mread_file_to_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestscenario_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(testscenario_path)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(testscenario_list)\n",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m, in \u001b[0;36mread_file_to_list\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file_to_list\u001b[39m(file_path):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      3\u001b[0m         lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines]\n",
      "File \u001b[1;32me:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Dissertation-GPT\\\\evaluate\\\\bestScenario\\\\MatchaEnglishWebsite\\\\Add new topic.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "for usecase in usecase_name_list:\n",
    "  base_name = os.path.basename(usecase)\n",
    "  usecase_name =usecase\n",
    "  usecase_path = os.path.join (use_case_directory_path,f\"{usecase_name}.txt\" )\n",
    "  testscenario_path = os.path.join (test_scenario_directory_path,f\"{usecase_name}.txt\" )\n",
    "  testscenario_list = read_file_to_list(testscenario_path)\n",
    "  print(testscenario_path)\n",
    "  print(testscenario_list)\n",
    "  for testscenario in testscenario_list:\n",
    "    content = \"Test scenarios:\"+ testscenario+  \"\\nUse case:\" + read_file_content(usecase_path)\n",
    "    print(content)\n",
    "    testscenario = testscenario.replace('\"','').replace(':','').replace('?','').replace('*','').replace('/','')\n",
    "    testcase_path = os.path.join (save_testcase_path,f\"{usecase_name}-{testscenario}.txt\" )\n",
    "    testcase_raw_path = os.path.join (save_testcase_raw_path,f\"{usecase_name}-{testscenario}.txt\" )\n",
    "    promptTestCase = [\n",
    "    { \"role\": \"system\", \"content\": SYSTEM_PROMPT_8},\n",
    "    { \"role\": \"user\", \"content\": content}\n",
    "    ]\n",
    "    gpt_response = askJSON(promptTestCase, client, model)\n",
    "    json_data = json.loads(gpt_response)\n",
    "    write_json_to_txt_raw(json_data, testcase_raw_path)\n",
    "\n",
    "    promptSelfRef = [\n",
    "        { \"role\": \"system\", \"content\": SELF_REF},\n",
    "        { \"role\": \"user\", \"content\": \"Test scenario: \"+ testscenario + \"\\n\" + gpt_response}\n",
    "    ]\n",
    "    final_response = askJSON(promptSelfRef, client, model)\n",
    "    json_fin = json.loads(final_response)\n",
    "    write_json_to_txt(json_fin, testcase_path)\n",
    "  print(\"f{usecase_name} gen test case complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Test Case 1\": {\n",
      "    \"testCaseName\": \"Successful New Topic Creation\",\n",
      "    \"objective\": \"Verify that an administrator can successfully add a new English learning topic\",\n",
      "    \"testSteps\": [\n",
      "      \"Step 1: Log in as an administrator.\",\n",
      "      \"Step 2: Select the 'Add new topic' tab on the navigation bar.\",\n",
      "      \"Step 3: Enter a unique name for the topic in the name field.\",\n",
      "      \"Step 4: Enter a description for the topic in the description field.\",\n",
      "      \"Step 5: Select 'Save' to create the new topic.\"\n",
      "    ],\n",
      "    \"expectedResult\": \"The system redirects the administrator to the adding vocabulary to new topic section, and the new topic appears in the topic list.\",\n",
      "    \"explanation\": \"This test case verifies the basic flow of adding a new topic by an administrator, ensuring the system behaves as expected when all inputs are valid and unique.\"\n",
      "  },\n",
      "  \"Test Case 2\": {\n",
      "    \"testCaseName\": \"Attempt to Add Topic with Duplicate Name\",\n",
      "    \"objective\": \"Verify that the system prevents the creation of a new topic with a name that is already used\",\n",
      "    \"testSteps\": [\n",
      "      \"Step 1: Log in as an administrator.\",\n",
      "      \"Step 2: Select the 'Add new topic' tab on the navigation bar.\",\n",
      "      \"Step 3: Enter a name for the topic that is already used in the name field.\",\n",
      "      \"Step 4: Enter a description for the topic in the description field.\",\n",
      "      \"Step 5: Select 'Save' to attempt to create the new topic.\",\n",
      "      \"Step 6: Observe the notification and enter a new, unique name in the name field.\",\n",
      "      \"Step 7: Select 'Save' again to create the topic.\"\n",
      "    ],\n",
      "    \"expectedResult\": \"The system shows a notification that the name is already used, prompting the administrator to add another name. After entering a new name, the topic is successfully created.\",\n",
      "    \"explanation\": \"This test case covers the alternative flow where an administrator attempts to add a new topic with a duplicate name, ensuring the system properly handles duplicate names.\"\n",
      "  },\n",
      "  \"Test Case 3\": {\n",
      "    \"testCaseName\": \"Cancel Topic Creation\",\n",
      "    \"objective\": \"Verify that an administrator can cancel the process of adding a new topic at any time\",\n",
      "    \"testSteps\": [\n",
      "      \"Step 1: Log in as an administrator.\",\n",
      "      \"Step 2: Select the 'Add new topic' tab on the navigation bar.\",\n",
      "      \"Step 3: Begin to enter details for the new topic.\",\n",
      "      \"Step 4: Select 'Cancel' to stop adding the new topic.\"\n",
      "    ],\n",
      "    \"expectedResult\": \"The system stops the topic creation process and does not add a new topic to the topic list.\",\n",
      "    \"explanation\": \"This test case verifies the exception flow, ensuring that administrators have the option to cancel the topic creation process at any point.\"\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# print(gpt_response)\n",
    "json_data = json.loads(gpt_response)\n",
    "print(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
