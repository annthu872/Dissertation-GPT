{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "GPT_MODEL_3_5 = \"gpt-3.5-turbo-1106\"\n",
    "GPT_MODEL_4 = \"gpt-4-0125-preview\"\n",
    "\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "model = GPT_MODEL_4\n",
    "\n",
    "def ask(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "      # response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase_flow_no_condition = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_gen_no_condition_test_scenarios =\"\"\"\n",
    "I want you to work as a software engineering who has profound knowledge about software design and software testing.\n",
    "You will be provided with use case specification flows.\n",
    "Your task is to write one test scenario ony to test each flow.\n",
    "Return the test scenarios generated in json format.\n",
    "The JSON format should follow the following structure:\n",
    "{\n",
    "    \"Test Scenarios\":[ \"description of scenario 1\", \"description of scenario 2\"],\n",
    "  }\n",
    "An example of a test scenario: \"Verify that users can successfully create a new account with valid credentials.\"\n",
    "\"\"\"\n",
    "#  For example: The condition 'The system should display a list of available items' or 'User can select the available items' or 'Item must display item's informaiton' must be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Test Scenarios\": [\n",
      "    \"Verify that when the Admin presses the 'Lesson Management' tab at the Homepage, the system navigates back to step 2 in the basic flow and continues from there.\",\n",
      "    \"Verify that when the Admin presses the 'Cancel' button at step 13, and then chooses 'Stay' on the confirmation dialog, the dialog closes, the work on the question is kept, and the Admin can successfully save the question by pressing the 'Save' button.\",\n",
      "    \"Verify that when the Admin presses the back button on the browser at step 13, the system redirects the Admin to the 'Word Information' page of the selected word and the question is not saved.\",\n",
      "    \"Verify that when the Admin presses the 'Cancel' button at step 13, and then chooses 'Confirm' on the confirmation dialog, the system redirects the Admin to the 'Word Information' page of the selected word and the question is not saved.\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "promptExtractCondtition = [\n",
    "    { \"role\": \"system\", \"content\": SYSTEM_PROMPT_gen_no_condition_test_scenarios},\n",
    "    { \"role\": \"user\", \"content\": usecase_flow_no_condition }\n",
    "  ]\n",
    "\n",
    "gpt_response = ask(promptExtractCondtition, client, model)\n",
    "print(gpt_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
