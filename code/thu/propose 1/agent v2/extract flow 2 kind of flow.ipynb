{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "GPT_MODEL_3_5 = \"gpt-3.5-turbo-1106\"\n",
    "GPT_MODEL_4 = \"gpt-4-0125-preview\"\n",
    "\n",
    "OPEN_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()\n",
    "model = GPT_MODEL_4\n",
    "\n",
    "def ask(prompt, client, model, temperature = 0):\n",
    "    response = None\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=prompt,\n",
    "      temperature=temperature,\n",
    "      # response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase_flow=\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_name = \"\"\"\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_print_no_condition_flow =\"\"\"\n",
    "I want you to work as a software engineering who has profound knowledge about software design and software testing.\n",
    "You will be provided with a use case specification flow and a list of flow names.\n",
    "Extract all the contents of flows which flow names are in the given list of flow names and all the contents of flows which flow names are not in the given list of flow names. \n",
    "Return the flows in json format.\n",
    "{\n",
    "  \"In\":{ \n",
    "  Name of flow 1:   {content of flow 1},\n",
    "  Name of flow 2:   {content of flow 2 }\n",
    " }\n",
    " \"Not in\":{ \n",
    "  Name of flow 1:   {content of flow 1},\n",
    "  Name of flow 2:   {content of flow 2 }\n",
    " }\n",
    "}\n",
    "\"\"\"\n",
    "#  For example: The condition 'The system should display a list of available items' or 'User can select the available items' or 'Item must display item's informaiton' must be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"In\": {\n",
      "    \"Alternative flow 1\": {\n",
      "      \"Step 3\": \"User clicks on the tab with the status name they want system to filter the order.\",\n",
      "      \"Step 4\": \"System shows only order with the corresponding chosen status.\"\n",
      "    },\n",
      "    \"Alternative flow 2\": {\n",
      "      \"Step 3\": \"User fills in one of these options of shop's name, order's ID or product's ID in the search bar.\",\n",
      "      \"Step 4\": \"User press enter.\",\n",
      "      \"Step 5\": \"System shows orders with keyword corresponding to user input.\"\n",
      "    }\n",
      "  },\n",
      "  \"Not in\": {\n",
      "    \"Main flow\": {\n",
      "      \"Step 1\": \"User clicks on the personal name and avatar section at the top right of the platform's page.\",\n",
      "      \"Step 2\": \"System redirects user to their personal bought order page. There are a list of all orders user have choose to bought and their information and status. On the top of the list there is a bar with multiple tabs, each tab is named after a state of an order including All, Waiting for payment, Delivering, Waiting to deliver, Finished, Cancelled and Returned. There is a search bar below the status bar for searching order.\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "promptExtractCondtition = [\n",
    "    { \"role\": \"system\", \"content\": SYSTEM_PROMPT_print_no_condition_flow},\n",
    "    { \"role\": \"user\", \"content\": usecase_flow + flows_name }\n",
    "  ]\n",
    "\n",
    "gpt_response = ask(promptExtractCondtition, client, model)\n",
    "print(gpt_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
